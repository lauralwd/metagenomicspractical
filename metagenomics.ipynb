{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "for i in ./metagenomics/mapping/*.bam ;\n",
    "    do echo $i.sorted\n",
    "    samtools sort -o \"$i.sorted\" \"$i\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove the samtools view directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pwd\n",
    "du -h ./metagenomics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ....yourdirectoryname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "samtools help page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!samtools view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run samtools view to view your BAM files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!samtools view ....yourbamsortedbam | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Binning with MetaBat </h2>\n",
    "\n",
    "Now that we have the reads, the scaffolds and the mapping of the reads on the scaffolds we can continue with the binning. In metagenomics, binning is the process of grouping reads or contigs and assigning them to operational taxonomic units. Binning methods can be based on either compositional features or alignment (similarity), or both. Metabat uses both the contig depth and tetra-nucleotide frequencies to bin the contigs. Every bin will represent one operational taxonomic unit that can be found in the metagenome.\n",
    "\n",
    "<b>Assignment:</b><br>\n",
    "Run the script provided in /metagenomics/scripts/jgi_summarize_bam_contig_depths to calculate the average depth per contig. <br>\n",
    "Then run metabat to bin the contigs, dont forget to include the previously included contig depths in the metabat command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./metagenomics/scripts/jgi_summarize_bam_contig_depths -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the contig depth per scaffold<br>\n",
    "hint: a glob looks like this directoryname/* and includes all files included in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./metagenomics/scripts/jgi_summarize_bam_contig_depths --outputDepth "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metabat help page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!metabat -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a new directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run metabat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!metabat -i -o -t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking completeness and contamination using CheckM </h2>\n",
    "\n",
    "Now that we have the bins made with metabat we can check them for contamination and completeness (quality), for this we will use CheckM. CheckM provides a set of tools for assessing the quality of genomes recovered from isolates, single cells, or metagenomes. It provides robust estimates of genome completeness and contamination by using collocated sets of genes that are ubiquitous and single-copy within a phylogenetic lineage (also called marker/signature genes). http://ecogenomics.github.io/CheckM/\n",
    "\n",
    "As you will be able to see in the checkm help pages, checkm has a workflow (lineage_wf) that will run all nessecary steps to asses bin quality. \n",
    "\n",
    "Lineage_wf (lineage-specific workflow) steps: <br>\n",
    "- The tree command places genome bins into a reference genome tree. <br>\n",
    "- The lineage_set command creates a marker file indicating lineage-specific marker sets suitable for evaluating each genome. <br>\n",
    "- This marker file is passed to the analyze command in order to identify marker genes and estimate the completeness and contamination of each genome bin.  <br>\n",
    "- Finally, the qa command can be used to produce different tables summarizing the quality of each genome bin. <br>\n",
    "\n",
    "\n",
    "<b>Assignment:</b><br>\n",
    "Sadly for this exercise the virtual machines we are using are not powerfull enough, therefore we provide the results of the first steps of the CheckM workflow up until the qa command (lineage_wf). Scan the help pages of CheckM to find out the correct command to finish the CheckM analysis. \n",
    "\n",
    "(OPTIONAL: you can try to find out what the limiting factor is of lineage_wf using !/usr/bin/time --verbose) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!checkm -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!checkm lineage_wf -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checkm qa help page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!checkm qa -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run checkm qa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!checkm qa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(think and discuss these questions) <br>\n",
    "\n",
    "What did you do? <br>\n",
    "Where is your output? <br>\n",
    "What does your output look like? <br>\n",
    "What can you say about the bins with this output? <br>\n",
    "What can you say about lineages of the bins?<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Genome annotation with Prokka</h2>\n",
    "\n",
    "Now that we some extra information about our bins, we can continue to analyze the high quality bins. The final CheckM results will give you a good overview of the bins with low contamination and high completeness and also shows the lowest taxonomic rank of the bin. Pick a bin that you think is interesting to further study.\n",
    "\n",
    "With this bin we are going to do some genome annotation. Whole genome annotation is the process of identifying features of interest in a set of genomic DNA sequences, and labelling them with useful information. Prokka is a software tool to annotate bacterial, archaeal and viral genomes quickly and produce standards-compliant output files.\n",
    "\n",
    "<b>Assignment:</b><br>\n",
    "Have a look at the prokka help pages below and come up with the right command to run prokka. (HINT: look at the Usage tag to run prokka on default mode, think of threads, use --centre X --compliant to stop prokkas complaints about ugly contig names, direct the output towars metagenomics/prokka)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!prokka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a directory for the prokka output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prokka help page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!prokka -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run prokka:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!prokka --cpus --outdir "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(think and discuss these questions) <br>\n",
    "\n",
    "What did you do? <br>\n",
    "Where is your output? <br>\n",
    "What does your output look like? <br>\n",
    "Do you know what all the output files are or mean? <br>\n",
    "\n",
    "(HINT: you can look at the prokka files in the same way we looked at the reads and scaffold earlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>investigating prokka output</b><br>\n",
    "to investigate the prokka output you can use two webservers that both are able to place the annotations from prokka in KEGG pathways.<br>\n",
    "\n",
    "(1) prokka gives uniprot IDs in the gff files first we will collect these IDs,\n",
    "(2) since we have Uniprot IDs from prokka we are going to convert these to KO IDs that can be used by KEGG using this website:<br>\n",
    "http://www.uniprot.org/uploadlists/\n",
    "\n",
    "(3) then you can put your IDs in both websites and investigate the pathways\n",
    "http://www.genome.jp/kegg/tool/map_module.html<br>\n",
    "http://pathways.embl.de/iPath2.cgi#<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view prokka output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!less ....yourprokkaoutput.gff | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take the uniprot IDs out of the gff file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -o 'UniProt.*' ....yourprokkaoutput | cut -d';' -f1 | cut -d':' -f2 > listofuniprotIDs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
