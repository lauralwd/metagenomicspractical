{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binning part 1: calculate depth\n",
    "\n",
    "Now we have all ingredients to continue binning: the scaffolds and bam files containing reads mapped on those scaffolds. \n",
    "In metagenomics, binning is the process of grouping reads or contigs and assigning them to operational taxonomic units. \n",
    "Binning methods can be based on either compositional features, alignment (similarity), or both.\n",
    "`metabat2` uses both the contig depth and tetra-nucleotide frequencies to bin the contigs. \n",
    "Every bin will ideally represent one microbial genome from one particular microbe that was in the original DNA extraction.\n",
    "\n",
    "The first step in the binning process, is to calculate the contig depths from all bam files that were created before.\n",
    "All these depths are stored in one big table, which is then passed to `metabat2`.\n",
    "We achieve this with a script that comes with `metabat2`: `jgi_summarize_bam_contig_depths`\n",
    "\n",
    "**[DO:] See how the** `jgi_summarize_bam_contig_depths` **script works:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jgi_summarize_bam_contig_depths 2.15 (Bioconda) 2020-01-04T21:10:40\n",
      "Usage: jgi_summarize_bam_contig_depths <options> sortedBam1 [ sortedBam2 ...]\n",
      "where options include:\n",
      "\t--outputDepth       arg  The file to put the contig by bam depth matrix (default: STDOUT)\n",
      "\t--percentIdentity   arg  The minimum end-to-end % identity of qualifying reads (default: 97)\n",
      "\t--pairedContigs     arg  The file to output the sparse matrix of contigs which paired reads span (default: none)\n",
      "\t--unmappedFastq     arg  The prefix to output unmapped reads from each bam file suffixed by 'bamfile.bam.fastq.gz'\n",
      "\t--noIntraDepthVariance   Do not include variance from mean depth along the contig\n",
      "\t--showDepth              Output a .depth file per bam for each contig base\n",
      "\t--minMapQual        arg  The minimum mapping quality necessary to count the read as mapped (default: 0)\n",
      "\t--weightMapQual     arg  Weight per-base depth based on the MQ of the read (i.e uniqueness) (default: 0.0 (disabled))\n",
      "\t--includeEdgeBases       When calculating depth & variance, include the 1-readlength edges (off by default)\n",
      "\t--maxEdgeBases           When calculating depth & variance, and not --includeEdgeBases, the maximum length (default:75)\n",
      "\t--referenceFasta    arg  The reference file.  (It must be the same fasta that bams used)\n",
      "\n",
      "Options that require a --referenceFasta\n",
      "\t--outputGC          arg  The file to print the gc coverage histogram\n",
      "\t--gcWindow          arg  The sliding window size for GC calculations\n",
      "\t--outputReadStats   arg  The file to print the per read statistics\n",
      "\t--outputKmers       arg  The file to print the perfect kmer counts\n",
      "\n",
      "Options to control shredding contigs that are under represented by the reads\n",
      "\t--shredLength       arg  The maximum length of the shreds\n",
      "\t--shredDepth        arg  The depth to generate overlapping shreds\n",
      "\t--minContigLength   arg  The mimimum length of contig to include for mapping and shredding\n",
      "\t--minContigDepth    arg  The minimum depth along contig at which to break the contig\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jgi_summarize_bam_contig_depths -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to find the **usage line** first.\n",
    "Then make sure you find the `--outputDepth` option. \n",
    "Notice that the help page tells you to supply an arg(ument) where to store the depth output file. \n",
    "Specify a path to a file that this script will create. Something like this:\n",
    "\n",
    "> ./script --outputDepth /path/to/depth_matrix.tab\n",
    "\n",
    "Remember than you can use bash to point to multiple files with a \"glob\" or \"asterisk\".\n",
    "A glob looks like this directory name/* and includes all files included in the directory.\n",
    "\n",
    "Try using the `*` with `ls` first. List all sorted bam files you created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/sorted/L1.sorted.bam  ./data/sorted/P1.sorted.bam\n",
      "./data/sorted/L2.sorted.bam  ./data/sorted/P2.sorted.bam\n",
      "./data/sorted/L3.sorted.bam  ./data/sorted/P3.sorted.bam\n"
     ]
    }
   ],
   "source": [
    "ls ./data/sorted/*.sorted.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[DO:] Run the script** `jgi_summarize_bam_contig_depths` **to calculate the average depth per contig over all six samples.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output depth matrix to ./data/depth_matrix.tab\n",
      "jgi_summarize_bam_contig_depths 2.15 (Bioconda) 2020-01-04T21:10:40\n",
      "Output matrix to ./data/depth_matrix.tab\n",
      "0: Opening bam: ./data/sorted/L1.sorted.bam\n",
      "1: Opening bam: ./data/sorted/L2.sorted.bam\n",
      "2: Opening bam: ./data/sorted/L3.sorted.bam\n",
      "3: Opening bam: ./data/sorted/P1.sorted.bam\n",
      "1: Opening bam: ./data/sorted/P3.sorted.bam\n",
      "0: Opening bam: ./data/sorted/P2.sorted.bam\n",
      "Processing bam files\n",
      "Thread 1 finished: L2.sorted.bam with 2017636 reads and 1591478 readsWellMapped\n",
      "Thread 2 finished: L3.sorted.bam with 2019434 reads and 1574839 readsWellMapped\n",
      "Thread 0 finished: L1.sorted.bam with 2016438 reads and 1580618 readsWellMapped\n",
      "Thread 3 finished: P1.sorted.bam with 2024982 reads and 1102782 readsWellMapped\n",
      "Thread 1 finished: P3.sorted.bam with 2023328 reads and 1151952 readsWellMapped\n",
      "Thread 0 finished: P2.sorted.bam with 2020648 reads and 1194925 readsWellMapped\n",
      "Creating depth matrix file: ./data/depth_matrix.tab\n",
      "Closing most bam files\n",
      "Closing last bam file\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "jgi_summarize_bam_contig_depths --outputDepth ./data/depth_matrix.tab ./data/sorted/*.sorted.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this process is the input for MetaBAT in the next step. \n",
    "After the jgi script finishes, make sure you check that the file contains a table. \n",
    "If so, please remove all BAM files. We don't need these anymore.\n",
    "\n",
    "**[DO:] Check if your depth matrix contains data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contigName\tcontigLen\ttotalAvgDepth\tL1.sorted.bam\tL1.sorted.bam-var\tL2.sorted.bam\tL2.sorted.bam-var\tL3.sorted.bam\tL3.sorted.bam-var\tP1.sorted.bam\tP1.sorted.bam-var\tP2.sorted.bam\tP2.sorted.bam-var\tP3.sorted.bam\tP3.sorted.bam-var\n",
      "NODE_1_length_1935275_cov_24.6805_ID_23901540\t1.93528e+06\t3.81973\t0.384547\t0.40742\t0.559138\t0.59541\t0.264181\t0.276061\t1.40386\t1.48422\t1.13602\t1.17447\t0.0719824\t0.0750967\n",
      "NODE_2_length_1021023_cov_23.722_ID_28578184\t1.02102e+06\t3.79263\t0.361356\t0.370018\t0.559212\t0.616769\t0.260588\t0.274248\t1.37231\t1.4455\t1.16247\t1.26335\t0.0766912\t0.0846405\n",
      "NODE_3_length_872793_cov_26.0458_ID_35712810\t872793\t4.08657\t0.397981\t0.416854\t0.597986\t0.629371\t0.276378\t0.292554\t1.51594\t1.60846\t1.21\t1.22886\t0.0882858\t0.0974476\n",
      "NODE_4_length_853167_cov_25.0814_ID_23902252\t853167\t3.95794\t0.384594\t0.395542\t0.59181\t0.659878\t0.268649\t0.282336\t1.45993\t1.50359\t1.1704\t1.21212\t0.0825517\t0.0909625\n",
      "NODE_5_length_723368_cov_22.0639_ID_32380821\t723368\t3.54784\t0.576476\t0.602873\t0.49381\t0.535239\t0.308742\t0.321746\t0.65946\t0.690835\t1.42751\t1.54562\t0.0818356\t0.090467\n",
      "NODE_6_length_592196_cov_27.8287_ID_32359880\t592196\t4.46972\t1.23031\t1.31669\t0.910303\t0.964396\t1.20794\t1.25681\t0.011945\t0.014408\t0.355303\t0.361317\t0.753918\t0.804243\n",
      "NODE_7_length_571573_cov_24.8726_ID_32329659\t571573\t3.87899\t0.88336\t0.931592\t0.851431\t0.898885\t0.888109\t0.960841\t0.450843\t0.484171\t0.183012\t0.183082\t0.622238\t0.673206\n",
      "NODE_8_length_486458_cov_22.6157_ID_32183008\t486458\t3.49845\t0.569483\t0.601542\t0.486603\t0.500474\t0.316542\t0.325059\t0.640236\t0.666413\t1.39795\t1.41065\t0.087642\t0.0974081\n",
      "NODE_9_length_472787_cov_23.2794_ID_23901976\t472787\t3.66833\t0.343202\t0.345515\t0.584793\t0.636413\t0.255867\t0.271952\t1.33483\t1.39462\t1.07996\t1.14636\t0.0696793\t0.0723315\n"
     ]
    }
   ],
   "source": [
    "head data/depth_matrix.tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[DO:] When you're sure, remove the sorted bams:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf ./data/sorted # double- and triple-check that your depth matrix is OK before removing the sorted bam files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth matrix visualisation\n",
    "Now you have your depth_matrix, let's take a moment and reflect upon what this matrix does and how it helps in binning the microbial contigs. \n",
    "For this part, we will visualise the depth_matrix file in excel (or a similar spreadsheet editor) on your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[DO:] Follow these steps:**\n",
    "1. Download the depth_matrix to your personal computer.\n",
    "2. The depth matrix is a big table in which columns are delimited by TABs. Open your data in excel and make sure all data is displayed as columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **[Q:] interpret the table**\n",
    "  1. What do the columns represent?\n",
    "  2. What do the rows represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **[A:]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[DO:]**\n",
    "\n",
    "4. For clarity, remove all columns except those that display the depth data.\n",
    "5. Check if you have one column per sample.\n",
    "6. Find the option for conditional formatting, filling the cells with colour depending on their content.\n",
    "7. Color all cells in the excel sheet according to a colour gradient with three colors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **[Q:] interpret the table**\n",
    "  1. Can you identify two rows with a similar colour pattern,\n",
    "  2. what does that mean if these two have a similar colour pattern?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **[A:]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now move on to binning part2!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
